"""
Assistant P√©dagogique avec GPT-2 - VERSION FINALE
TP NLP - Compl√©tion du projet selon le PDF fourni
"""

# ============================
# IMPORTS
# ============================
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch
import re

# ============================
# QUESTION 2 : CHARGEMENT DU MOD√àLE
# ============================
print("Chargement du mod√®le GPT-2...")
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2LMHeadModel.from_pretrained("gpt2")

# CORRECTION COMPL√àTE : Configurer le tokenizer
tokenizer.pad_token = tokenizer.eos_token

print("‚úÖ Mod√®le GPT-2 charg√© !\n")

# ============================
# QUESTION 1 : PR√âTRAITEMENT DU TEXTE
# ============================
def preprocess_text(texte):
    """
    Pr√©traitement simple du texte p√©dagogique
    R√©duit le bruit et homog√©n√©ise l'entr√©e
    """
    # 1. Supprimer les caract√®res sp√©ciaux non d√©sir√©s
    texte = re.sub(r'[^\w\s.,!?:;\-√©√®√™√´√†√¢√§√¥√∂√ª√º√ß√â√à√ä√ã√Ä√Ç√Ñ√î√ñ√õ√ú√á]', '', texte)

    # 2. Normaliser les espaces
    texte = re.sub(r'\s+', ' ', texte)
    texte = texte.strip()

    # 3. Remplacer les sauts de ligne multiples
    texte = texte.replace('\n', ' ').replace('\r', ' ')

    return texte

# ============================
# QUESTION 3 : REFORMULATION DE TEXTE
# ============================
def reformuler_texte(texte, max_length=100):
    """
    Reformule un texte p√©dagogique de mani√®re simple
    UTILISE UN PROMPT EN ANGLAIS POUR DE MEILLEURS R√âSULTATS
    """
    # PROMPT EN ANGLAIS + demande de r√©ponse en fran√ßais
    prompt = "Explain the following concept in simple French: " + texte

    # Encodage avec attention_mask
    inputs = tokenizer.encode(prompt, return_tensors="pt")
    attention_mask = torch.ones_like(inputs)

    # G√©n√©ration du texte avec TOUS les param√®tres n√©cessaires
    outputs = model.generate(
        inputs,
        attention_mask=attention_mask,  # CORRECTION IMPORTANTE
        max_length=max_length,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        temperature=0.7,  # Ajout√© pour de meilleurs r√©sultats
        pad_token_id=tokenizer.pad_token_id,
        eos_token_id=tokenizer.eos_token_id,
        repetition_penalty=1.1  # √âvite la r√©p√©tition
    )

    # D√©codage
    resultat = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Retirer le prompt du r√©sultat
    if prompt in resultat:
        resultat = resultat.replace(prompt, "").strip()

    return resultat

# ============================
# QUESTION 4 : EFFET DU PROMPT
# ============================
def tester_prompts_differents(texte, max_length=120):
    """
    Teste deux prompts diff√©rents sur le m√™me texte
    TOUS LES PROMPTS SONT EN ANGLAIS
    """
    # Prompt 1 : Simple
    prompt_simple = "Explain in simple French: " + texte

    # Prompt 2 : Avec exemple
    prompt_exemple = "Explain in French and give a concrete example: " + texte

    resultats = {}

    prompts = {
        "Reformulation simple": prompt_simple,
        "Reformulation avec exemple": prompt_exemple
    }

    for nom, prompt in prompts.items():
        inputs = tokenizer.encode(prompt, return_tensors="pt")
        attention_mask = torch.ones_like(inputs)

        outputs = model.generate(
            inputs,
            attention_mask=attention_mask,  # CORRECTION
            max_length=max_length,
            do_sample=True,
            top_k=50,
            top_p=0.9,
            temperature=0.8,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id
        )

        texte_genere = tokenizer.decode(outputs[0], skip_special_tokens=True)
        if prompt in texte_genere:
            texte_genere = texte_genere.replace(prompt, "").strip()
        resultats[nom] = texte_genere

    return resultats

# ============================
# QUESTION 4 bis : G√âN√âRATION DE QCM
# ============================
def generer_qcm(texte, max_length=200):
    """
    G√©n√®re un mini QCM √† partir d'un texte p√©dagogique
    PROMPT EN ANGLAIS
    """
    # Prompt orient√© QCM - en anglais
    prompt = (
        "Based on this text, create a short quiz in French with 2 questions "
        "and 3 answer choices per question. Include the correct answer.\n\n"
        "Text: " + texte + "\n\n"
        "Quiz:"
    )

    # Encodage
    inputs = tokenizer.encode(prompt, return_tensors="pt")
    attention_mask = torch.ones_like(inputs)

    # G√©n√©ration
    outputs = model.generate(
        inputs,
        attention_mask=attention_mask,  # CORRECTION
        max_length=max_length,
        do_sample=True,
        top_k=40,
        top_p=0.85,
        temperature=0.9,
        pad_token_id=tokenizer.pad_token_id,
        eos_token_id=tokenizer.eos_token_id
    )

    # D√©codage
    qcm = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Nettoyage
    if prompt in qcm:
        qcm = qcm.replace(prompt, "").strip()

    return qcm

# ============================
# FONCTION PRINCIPALE - D√âMONSTRATION
# ============================
def main():
    print("=" * 60)
    print("ASSISTANT P√âDAGOGIQUE GPT-2 - TP NLP")
    print("=" * 60)

    # Texte p√©dagogique d'exemple
    texte_exemple = """
    La photosynth√®se est un processus utilis√© par les plantes pour convertir 
    l'√©nergie lumineuse en √©nergie chimique. Elle se d√©roule dans les chloroplastes 
    et n√©cessite du dioxyde de carbone, de l'eau et de la lumi√®re.
    """

    print("\nüìù TEXTE ORIGINAL :")
    print(texte_exemple)

    # 1. Pr√©traitement
    texte_propre = preprocess_text(texte_exemple)
    print("\n‚úÖ TEXTE APR√àS PR√âTRAITEMENT :")
    print(texte_propre)

    # 2. Reformulation (Question 3)
    print("\n" + "=" * 60)
    print("QUESTION 3 : REFORMULATION DE TEXTE")
    print("=" * 60)

    texte_reformule = reformuler_texte(texte_propre, max_length=120)
    print("üìù R√©sultat de la reformulation :")
    print(texte_reformule)

    # 3. Effet des prompts (Question 4)
    print("\n" + "=" * 60)
    print("QUESTION 4 : EFFET DU PROMPT")
    print("=" * 60)

    resultats_prompts = tester_prompts_differents(texte_propre)

    for nom, resultat in resultats_prompts.items():
        print(f"\nüîπ {nom} :")
        print(resultat)

    # 4. G√©n√©ration de QCM (Question 4 bis)
    print("\n" + "=" * 60)
    print("QUESTION 4 bis : G√âN√âRATION DE QCM")
    print("=" * 60)

    qcm_genere = generer_qcm(texte_propre, max_length=250)
    print("üìù QCM g√©n√©r√© :")
    print(qcm_genere)

    # 5. Analyse critique (Question 5)
    print("\n" + "=" * 60)
    print("QUESTION 5 : ANALYSE CRITIQUE")
    print("=" * 60)
    print("""
    LIMITES DE GPT-2 DANS UN CONTEXTE √âDUCATIF :

    1. LANGUE : Principalement entra√Æn√© sur l'anglais, fran√ßais limit√©
    2. PR√âCISION : Risque d'inexactitudes factuelles
    3. CONTEXTE : Ne comprend pas le niveau de l'apprenant
    4. COH√âRENCE : Peut g√©n√©rer des contradictions
    5. V√âRIFICATION : Pas de validation automatique
    6. BIAIS : Reproduction des biais du dataset
    7. QCM : Options parfois peu pertinentes
    """)

    print("\n" + "=" * 60)
    print("‚úÖ PROJET TERMIN√â AVEC SUCC√àS !")
    print("=" * 60)

# ============================
# EX√âCUTION
# ============================
if __name__ == "__main__":
    main()